{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Presented by: Reza Saadatyar (2024-2025)**<br/>\n",
    "**E-mail: Reza.Saadatyar@outlook.com**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1Ô∏è‚É£ CPU (Central Processing Unit) & GPU (Graphics Processing Unit)**<br/>\n",
    "`CPU:`<br/>\n",
    "  - Designed for general-purpose computing.\n",
    "  - Optimized for sequential tasks.\n",
    "  - Has a few powerful cores.\n",
    "  - Excellent at handling complex logic and single-threaded applications.\n",
    "  \n",
    "`GPU:`<br/>\n",
    "  - Designed for parallel processing.\n",
    "  - Has thousands of smaller, less powerful cores.\n",
    "  - GPUs offer far faster numerical computing than CPUs.\n",
    "  - Optimized for tasks that can be divided into many independent calculations.\n",
    "  - Excellent for tasks like matrix operations, which are common in deep learning.\n",
    "\n",
    "Putting a tensor on GPU using `to(device)` (e.g. `some_tensor.to(device)`) returns a copy of that tensor, e.g. the same tensor will be on CPU and GPU. `some_tensor = some_tensor.to(device)`  \n",
    "\n",
    "**2Ô∏è‚É£ N-d Tensor**<br/> \n",
    "A tensor is a multi-dimensional array of numerical values. Tensor computation (like numpy) with strong GPU acceleration.<br/>\n",
    "`0-dimensional (Scalar):` A single number, e.g., 5, 3.14, -10. A <font color='red'><b>scalar</b></font> is a single number and in tensor-speak it's a zero dimension tensor.<br/>\n",
    "`1-dimensional (Vector):` A list of numbers, e.g., [1, 2, 3]. A <font color='blue'><b>vector</b></font> is a single dimension tensor but can contain many numbers.<br/>\n",
    "`2-dimensional (Matrix):` A table of numbers, e.g., [[1, 2], [3, 4]]. <font color='green'><b>MATRIX</b></font>  has two dimensions.<br/>\n",
    "`3-dimensional (or higher):` Like a \"cube\" of numbers or more complex higher-dimensional structures. These are common for representing images, videos, and more.<br/>\n",
    "\n",
    "**üî∏ Tensor datatypes**<br/>\n",
    "There are many different [tensor datatypes available in PyTorch](https://pytorch.org/docs/stable/tensors.html#data-types). Some are specific for CPU and some are better for GPU.<br/>\n",
    "Generally if you see `torch.cuda` anywhere, the tensor is being used for GPU (since Nvidia GPUs use a computing toolkit called CUDA).<br/>\n",
    "The most common type (and generally the default) is `torch.float32` or `torch.float`.<br/>\n",
    "\n",
    "**3Ô∏è‚É£ Getting information from tensors**<br/>\n",
    "`shape` - what shape is the tensor? (some operations require specific shape rules)<br/>\n",
    "`dtype` - what datatype are the elements within the tensor stored in?<br/>\n",
    "`device` - what device is the tensor stored on? (usually GPU or CPU)<br/>\n",
    "\n",
    "**4Ô∏è‚É£ Math Operations**<br/>\n",
    "`Addition` ‚áí *a+b* or *torh.add(a, b)*<br/>\n",
    "`Substraction` ‚áí *a-b* or *torh.sub(a, b)*<br/>\n",
    "`Multiplication (element-wise)` ‚áí *axb* <br/>\n",
    "`Division` ‚áí *a/b* or *torh.div(a, b)*<br/>\n",
    "`Matrix multiplication` ‚áí `@` in Python is the symbol for matrix multiplication. [`torch.matmul()`](https://pytorch.org/docs/stable/generated/torch.matmul.html) or [`torch.mm()`](https://pytorch.org/docs/stable/generated/torch.mm.html)<br/>\n",
    "`torch.mean & torch.std`\n",
    "  \n",
    "**5Ô∏è‚É£ Special Arrays**<br/>\n",
    "`zeros`<br/>\n",
    "`ones`<br/>\n",
    "`empty`<br/>\n",
    "`eye`<br/>\n",
    "`full`<br/>\n",
    "`arange`<br/>\n",
    "`reshape`<br/>\n",
    "`linspace`<br/>\n",
    "\n",
    "üî∏ Using [`torch.zeros_like(input)`](https://pytorch.org/docs/stable/generated/torch.zeros_like.html) or [`torch.ones_like(input)`](https://pytorch.org/docs/1.9.1/generated/torch.ones_like.html) which return a tensor filled with zeros or ones in the same shape as the `input` respectively.\n",
    "\n",
    "**6Ô∏è‚É£ Random Arrays**<br/>\n",
    "`torch.rand:` Create a *n x m* tensor filled with random numbers from a uniform distribution on the interval [0, 1)<br/>\n",
    "`torch.randn:` Create a *n x m* tensor filled with random numbers from a normal distribution with mean 0 and variance 1. <br/>\n",
    "`torch.randint:` Create a *n x m* tensor filled with random integers generated uniformly between low (inclusive) and high (exclusive).<br/>\n",
    "\n",
    "üî∏ `torch.randperm(value):` Create a random permutation of integers from 0 to value.<br/>\n",
    "üî∏ `torch.permute(input, dims):` Permute the original tensor to rearrange the axis order.\n",
    "\n",
    "**7Ô∏è‚É£ Indexing & Slicing**<br/>\n",
    "`Indexing:` Use integer indices to specify the position of the element you want to retrieve (Accessing individual elements).<br/>\n",
    "`Slicing:` Slicing allows you to extract a sub-part of your tensor by specifying a range of indices using the colon : operator (Extracting sub-tensors).<br/>\n",
    "  - `start:end` (exclusive end)\n",
    "  - `start:` (from start to end of dimension)\n",
    "  - `:end` (from beginning to end of dimension)\n",
    "  - `:` (all elements)\n",
    "  - `start:end:step` (start to end with given step)\n",
    "\n",
    "**8Ô∏è‚É£ Unsqueeze & squeeze**<br/>\n",
    "The `squeeze()` method removes all singleton dimensions from a tensor. It will reduce the number of dimensions by removing the ones that have a size of 1.<br/>\n",
    "The `unsqueeze()` method adds a singleton dimension at a specified position in a tensor. It will increase the number of dimensions by adding a size of 1 dimension at a specific position.<br/>\n",
    "\n",
    "**9Ô∏è‚É£ PyTorch tensors & NumPy**<br/>\n",
    "[`torch.from_numpy(ndarray)`](https://pytorch.org/docs/stable/generated/torch.from_numpy.html)  NumPy array ‚Üí PyTorch tensor<br/>\n",
    "[`torch.Tensor.numpy()`](https://pytorch.org/docs/stable/generated/torch.Tensor.numpy.html)  PyTorch tensor ‚Üí NumPy array.<br/>\n",
    "\n",
    "**üîü Array Manipulation**<br/>\n",
    "`torch.stack:` Stacks tensors along a new dimension.<br/>\n",
    "`torch.cat:` Concatenates tensors along an existing dimension.<br/>\n",
    "`torch.split:` Dividing an tensor into multiple sub-arrays.<br/>\n",
    "`torch.flatten:` Compresses a tensor into a contiguous 1D representation.<br/>\n",
    "`torch.clone:` Creates a deep copy.<br/>\n",
    "`torch.repeat:` Repeats the tensor along specified dimensions..<br/>\n",
    "`torch.tile:` Repeats the tensor along specified dimensions. <br/>\n",
    "`torch.unique:` Finding unique elements in a tensor.<br/>\n",
    "`torch.sort, torch.argsort:` Returns both the sorted tensor and the indices of the sorted elements.<br/>\n",
    "`torch.argmax, torch.argmin:` Finding the indices of the maximum and minimum values. For example, <font color=\"green\"><b>torch.argmax()</b></font> and <font color=\"green\"><b>torch.argmin()</b></font>.<br/>\n",
    "`torch.where(condition, x, y), torch.argwhere (using torch.nonzero), extract(using arr[cond]):` Conditional operations. <font color=\"green\"><b>torch.where()</b></font> returns elements based on a condition, <font color=\"green\"><b>torch.nonzero()</b></font> returns indices of elements that satisfy a condition, and <font color=\"green\"><b>arr[cond]</b></font> extracts elements based on a condition.<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='#FF000e' size=\"4.5\" face=\"Arial\"><b>Import modules</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch  #  torch.__version__  -> '2.5.1+cpu'\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='#00ff0e' size=\"4.5\" face=\"Arial\"><b>1Ô∏è‚É£ CPU vs GPU</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'nvidia-smi' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# To check if you've got access to a Nvidia GPU, you can run `!nvidia-smi` where the `!` (also called bang) means\n",
    "# \"run this on the command line\".\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.backends.mps.is_available() # Check for GPU on a Mac\n",
    "torch.cuda.is_available()           # Check for GPU on Wind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device = 'cpu', device_count = 0\n"
     ]
    }
   ],
   "source": [
    "# Set the device to 'cuda' (GPU) if a CUDA-compatible GPU is available, otherwise set it to 'cpu' (CPU)\n",
    "# This is commonly used in PyTorch to ensure computations are performed on the GPU for faster processing when available\n",
    "# device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"  # Set device type\n",
    "device_count =  torch.cuda.device_count()  # Count number of devices\n",
    "print(f\"{device = }, {device_count = }\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3]), array([1, 2, 3]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Putting tensors (and models) on the GPU or CPU\n",
    "tensor = torch.tensor([1, 2, 3]) # Create tensor (default on CPU)\n",
    "tensor_on_gpu = tensor.to(device) # Move tensor to GPU (if available)\n",
    "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()  # Moving tensors back to the CPU using .cpu().numpy()\n",
    "tensor_on_gpu, tensor_back_on_cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='#001240ee' size=\"4.5\" face=\"Arial\"><b>2Ô∏è‚É£ Scalar, Vector, Column vector, Matrix, & N-d Tensor</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.3333)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a 0-dimensional tensor (scalar) ‚Üí A 0D tensor represents a single value, similar to a scalar in mathematics\n",
    "torch.tensor(4/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = tensor([1, 2, 3]) --> a.__class__ = <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# Create a 1-dimensional tensor (vector) ‚Üí A 1D tensor is a list of values, similar to a vector in mathematics\n",
    "a = torch.tensor([1, 2, 3])\n",
    "print(f\"{a = } --> {a.__class__ = }\") # The `__class__` attribute shows the type of the object, which is `torch.Tensor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]])\n"
     ]
    }
   ],
   "source": [
    "# Create a 2-dimensional tensor (column vector) ‚Üí A 2D tensor is a matrix with rows and columns\n",
    "column_vector = torch.tensor([[1], [2], [3], [4]]) # A column vector with 4 rows and 1 column\n",
    "print(column_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n"
     ]
    }
   ],
   "source": [
    "# Create a 2-dimensional tensor (matrix) ‚Üí A 2D tensor is a matrix with rows and columns\n",
    "matrix = torch.tensor([[1, 2, 3],\n",
    "                       [4, 5, 6],\n",
    "                       [7, 8, 9]]\n",
    ")\n",
    "print(matrix) # A 2D tensor with shape (3, 3), representing a 3x3 matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2, 2, 5],\n",
      "         [3, 4, 0, 8]],\n",
      "\n",
      "        [[5, 6, 6, 7],\n",
      "         [4, 8, 1, 2]],\n",
      "\n",
      "        [[1, 1, 8, 9],\n",
      "         [0, 0, 2, 3]]])\n"
     ]
    }
   ],
   "source": [
    "# Create a 3-dimensional tensor\n",
    "# A 3D tensor can be thought of as a collection of matrices (2D tensors) stacked along a third dimension\n",
    "# Here, the tensor is created from a nested list structure with three levels:\n",
    "# - The outer list represents the \"depth\" or \"channels\" (3 in this case).\n",
    "# - The middle lists represent the rows of each matrix (2 in this case).\n",
    "# - The inner lists represent the columns of each matrix (4 in this case).\n",
    "tensor_3d = torch.tensor([[[1, 2, 2, 5],\n",
    "                           [3, 4, 0, 8]],\n",
    "\n",
    "                          [[5, 6, 6, 7],\n",
    "                           [4, 8, 1, 2]],\n",
    "\n",
    "                          [[1, 1, 8, 9],\n",
    "                           [0, 0, 2, 3]]]\n",
    ")\n",
    "print(tensor_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1, 2, 5, 4],\n",
      "          [3, 4, 1, 0]],\n",
      "\n",
      "         [[5, 6, 2, 3],\n",
      "          [7, 8, 6, 4]]]])\n"
     ]
    }
   ],
   "source": [
    "# Create a 4-dimensional tensor\n",
    "# A 4D tensor can be thought of as a collection of 3D tensors stacked along a fourth dimension\n",
    "# Here, the tensor is created from a nested list structure with four levels:\n",
    "# - The outer list represents the \"batch\" dimension (1 in this case).\n",
    "# - The next level represents the \"depth\" or \"channels\" (2 in this case).\n",
    "# - The next level represents the rows of each matrix (2 in this case).\n",
    "# - The innermost lists represent the columns of each matrix (4 in this case).\n",
    "tensor_4d = torch.tensor([[[[1, 2, 5, 4],\n",
    "                            [3, 4, 1, 0]],\n",
    "                           \n",
    "                           [[5, 6, 2, 3],\n",
    "                            [7, 8, 6, 4]]]]\n",
    ")\n",
    "\n",
    "# A 4D tensor with shape (1, 2, 2, 4), representing:\n",
    "# - 1 batch\n",
    "# - 2 channels/depth\n",
    "# - Each channel has 2 rows and 4 columns\n",
    "print(tensor_4d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n"
     ]
    }
   ],
   "source": [
    "# Create a tuple of tuples, where each inner tuple contains two integers\n",
    "a = tuple([(1, 2), \n",
    "           (3, 4), \n",
    "           (5, 6)])\n",
    "tensor_a = torch.tensor(a) # Convert the tuple of tuples into a PyTorch tensor\n",
    "print(tensor_a) # The resulting tensor is a 2D tensor with shape (3, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='#ff555e2' size=\"4.5\" face=\"Arial\"><b>3Ô∏è‚É£ Getting information from tensors</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float32, device(type='cpu'))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Default datatype for tensors is float32\n",
    "float_32_tensor = torch.tensor([1.0, 5.0, 6.0],\n",
    "                               dtype=None, # defaults to None, which is torch.float32 or whatever datatype is passed\n",
    "                               device=None, # defaults to None, which uses the default tensor type\n",
    "                               requires_grad=False) # if True, operations performed on the tensor are recorded \n",
    "\n",
    "float_32_tensor.dtype, float_32_tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = tensor(1.3333, dtype=torch.float64) --> a.shape = torch.Size([]), a.ndim = 0, a.size() = torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "# Create a 0-dimensional tensor (scalar) ‚Üí A 0D tensor represents a single value, similar to a scalar in mathematics\n",
    "# The tensor is explicitly set to have a data type of `torch.float64` (64-bit floating point) and is placed on the CPU\n",
    "a = torch.tensor(4/3, dtype=torch.float64, device=\"cpu\")\n",
    "\n",
    "# - `a.shape`: The shape of the tensor (empty tuple for 0D tensors)\n",
    "# - `a.ndim`: The number of dimensions (0 for a scalar)\n",
    "# - `a.size()`: The size of the tensor (same as shape for 0D tensors)\n",
    "print(f\"{a = } --> {a.shape = }, {a.ndim = }, {a.size() = }\")\n",
    "\n",
    "# Convert the tensor to a different data type, `torch.float16` (16-bit floating point)\n",
    "# This reduces the precision of the tensor but can save memory and improve performance\n",
    "a_float16 = a.type(torch.float16)\n",
    "# Alternatively, you can use `a.short()` to convert to a 16-bit integer, but this is not applicable here since the tensor is floating-point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#ff0051e2\" size=\"4.5\" face=\"Arial\"><b>4Ô∏è‚É£ Math Operations</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Addition:\n",
      "tensor([[ 6,  8],\n",
      "        [10, 12]])\n",
      "\n",
      "Subtraction:\n",
      "tensor([[-4, -4],\n",
      "        [-4, -4]])\n",
      "\n",
      "Element-wise Multiplication:\n",
      "tensor([[ 5, 12],\n",
      "        [21, 32]])\n",
      "\n",
      "Division:\n",
      "tensor([[0.2000, 0.3333],\n",
      "        [0.4286, 0.5000]])\n",
      "\n",
      "Matrix Multiplication:\n",
      "tensor([[19, 22],\n",
      "        [43, 50]])\n"
     ]
    }
   ],
   "source": [
    "# Create tensors\n",
    "a = torch.tensor([[1, 2], \n",
    "                  [3, 4]])\n",
    "\n",
    "b = torch.tensor([[5, 6], \n",
    "                  [7, 8]])\n",
    "\n",
    "# Addition\n",
    "add_result = a + b  # or torch.add(a, b)\n",
    "\n",
    "# Subtraction\n",
    "sub_result = a - b  # or torch.sub(a, b)\n",
    "\n",
    "# Element-wise multiplication\n",
    "mul_result = a * b\n",
    "\n",
    "# Division\n",
    "div_result = a / b  # or torch.div(a, b)\n",
    "\n",
    "# Matrix multiplication\n",
    "matmul_result = a @ b  # or torch.matmul(a, b) or torch.mm(a, b)\n",
    "\n",
    "print(f\"Addition:\\n{add_result}\")\n",
    "print(f\"\\nSubtraction:\\n{sub_result}\")\n",
    "print(f\"\\nElement-wise Multiplication:\\n{mul_result}\")\n",
    "print(f\"\\nDivision:\\n{div_result}\")\n",
    "print(f\"\\nMatrix Multiplication:\\n{matmul_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of all elements: tensor(2.5000)\n",
      "Mean along dimension 0: tensor([2., 3.])\n",
      "Mean along dimension 1: tensor([1.5000, 3.5000])\n",
      "Mean: 2.5\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "torch.mean(input, dim=None, keepdim=False, dtype=None)\n",
    "torch.mean(input, dim=None, keepdim=False, dtype=None)\n",
    "\"\"\"\n",
    "tensor = torch.tensor([[1.0, 2.0], \n",
    "                       [3.0, 4.0]])\n",
    "mean_all = torch.mean(tensor)  # Mean of all elements\n",
    "mean_dim0 = torch.mean(tensor, dim=0)  # Mean along dimension 0 (rows)\n",
    "mean_dim1 = torch.mean(tensor, dim=1)  # Mean along dimension 1 (columns)\n",
    "\n",
    "print(\"Mean of all elements:\", mean_all)\n",
    "print(\"Mean along dimension 0:\", mean_dim0)\n",
    "print(\"Mean along dimension 1:\", mean_dim1)\n",
    "\n",
    "# Convert the tensor to `float` type using `.float()` to ensure the mean is computed as a floating-point value\n",
    "mean_value = a.float().mean() # Calculate the mean of the tensor\n",
    "print(f\"Mean: {mean_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Std of all elements: tensor(1.2910)\n",
      "Std along dimension 0: tensor([1.4142, 1.4142])\n",
      "Std along dimension 1: tensor([0.7071, 0.7071])\n",
      "Standard Deviation: 1.29099440574646\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "torch.std(input, dim=None, unbiased=True, keepdim=False)\n",
    "unbiased: If True, uses Bessel's correction (divides by n-1 instead of n).\n",
    "keepdim: Whether to retain the reduced dimension in the output.\n",
    "\"\"\"\n",
    "x = torch.tensor([[1.0, 2.0], \n",
    "                  [3.0, 4.0]])\n",
    "std_all = torch.std(x)  # Std of all elements\n",
    "std_dim0 = torch.std(x, dim=0)  # Std along dimension 0 (rows)\n",
    "std_dim1 = torch.std(x, dim=1)  # Std along dimension 1 (columns)\n",
    "\n",
    "print(\"Std of all elements:\", std_all)\n",
    "print(\"Std along dimension 0:\", std_dim0)\n",
    "print(\"Std along dimension 1:\", std_dim1)\n",
    "\n",
    "# Convert the tensor to `torch.float32` type using `.type(torch.float32)` to ensure the standard deviation is computed as a floating-point value\n",
    "std_value = a.type(torch.float32).std() # Calculate the standard deviation of the tensor\n",
    "print(f\"Standard Deviation: {std_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#00ff21aa\" size=\"4.5\" face=\"Arial\"><b>5Ô∏è‚É£ Special Arrays</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a 2D tensor filled with ones\n",
    "torch.ones((2, 1))  # The tensor has a shape of (2, 1), meaning it has 2 rows and 1 column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a 3D tensor filled with zeros\n",
    "# The tensor has a shape of (3, 4, 3), meaning:\n",
    "# - 3 matrices (depth/channels)\n",
    "# - Each matrix has 4 rows and 3 columns\n",
    "torch.zeros((3, 4, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The tensor has a shape of (5, 4), meaning it has 5 rows and 4 columns\n",
    "torch.eye(5, 4) # The diagonal elements are set to 1, and all other elements are set to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 2, 2],\n",
       "        [2, 2, 2],\n",
       "        [2, 2, 2],\n",
       "        [2, 2, 2]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The tensor has a shape of (4, 3), meaning it has 4 rows and 3 columns\n",
    "torch.full([4, 3], fill_value=2) # All elements in the tensor are set to the `fill_value` (2 in this case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a 2x3 uninitialized tensor\n",
    "torch.empty(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "torch.arange(start=0, end, step=1, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)\n",
    "start: The starting value of the sequence (default is 0).\n",
    "end: The ending value of the sequence (exclusive).\n",
    "step: The step size between values (default is 1).\n",
    "dtype: The data type of the output tensor (e.g., torch.float32, torch.int64).\n",
    "requires_grad: If True, the tensor will track operations for automatic differentiation\n",
    "\"\"\"\n",
    "# Create a tensor with values from 0 to 9\n",
    "torch.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2],\n",
       "        [3, 4, 5]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor and reshape it\n",
    "tensor = torch.arange(6)  # 1D tensor with values 0 to 5\n",
    "tensor.reshape(2, 3)  # Reshape to 2x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.2500, 0.5000, 0.7500, 1.0000])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "torch.linspace(start, end, steps, *, out=None, dtype=None, device=None, requires_grad=False)\n",
    "start: The starting value of the sequence.\n",
    "end: The ending value of the sequence (inclusive).\n",
    "steps: The number of points in the sequence.\n",
    "dtype: The data type of the output tensor (e.g., torch.float32, torch.float64).\n",
    "requires_grad: If True, the tensor will track operations for automatic differentiation.\n",
    "\"\"\"\n",
    "# Create a tensor with 5 values evenly spaced between 0 and 1\n",
    "torch.linspace(0, 1, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#22aa1232\" size=\"4.5\" face=\"Arial\"><b>6Ô∏è‚É£ Random Arrays</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4657, 0.2328, 0.4527],\n",
       "        [0.5871, 0.4086, 0.1272],\n",
       "        [0.6373, 0.2421, 0.7312],\n",
       "        [0.7224, 0.1992, 0.6948]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(12) # Set a manual seed for reproducibility\n",
    "torch.rand((4, 3)) # Create a 2D tensor with random values uniformly distributed between 0 and 1 (shape of (4, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2138, -1.3780, -0.0546],\n",
       "        [ 0.4515,  0.7858, -1.0884],\n",
       "        [-0.5599, -0.9336,  0.0479],\n",
       "        [-0.0844, -0.1471,  0.7590]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(12) # Set a manual seed for reproducibility\n",
    "torch.randn((4, 3)) # Createa 2D tensor filled with random values, uniformly distributed with a mean of 0 and a variance of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[12,  3,  9],\n",
       "        [11,  2, 10],\n",
       "        [ 8,  3,  3],\n",
       "        [10, 11,  2]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set a manual seed for reproducibility\n",
    "torch.manual_seed(12)\n",
    "\n",
    "# Create a 2D tensor with random integer values within a specified range\n",
    "torch.randint(2, 13, (4, 3)) # The range is from 2 (inclusive) to 13 (exclusive) and a shape of (4, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#22aa1232\" size=\"4.5\" face=\"Arial\"><b>6Ô∏è‚É£ Randperm & permute</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 8, 7, 6, 4, 5, 2, 9, 1, 0])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\"\"\"\n",
    "# Create a random permutation of integers from 0 to 9\n",
    "torch.randperm(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous shape: torch.Size([224, 224, 3])\n",
      "New shape: torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\"\"\"\n",
    "# Create a tensor with a specific shape (224, 224, 3) using random values\n",
    "# This shape is commonly used for RGB images, where:\n",
    "# - 224 is the height\n",
    "# - 224 is the width\n",
    "# - 3 is the number of color channels (Red, Green, Blue)\n",
    "original = torch.rand(size=(224, 224, 3))\n",
    "\n",
    "# Permute the tensor to rearrange the order of its axes\n",
    "# The `permute()` method reorders the dimensions of the tensor\n",
    "# Here, the new order is (2, 0, 1), which means:\n",
    "# - The original axis 2 (channels) becomes the new axis 0\n",
    "# - The original axis 0 (height) becomes the new axis 1\n",
    "# - The original axis 1 (width) becomes the new axis 2\n",
    "permuted = original.permute(2, 0, 1)\n",
    "print(f\"Previous shape: {original.shape}\")\n",
    "print(f\"New shape: {permuted.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#bb1254ff\" size=\"4.5\" face=\"Arial\"><b>7Ô∏è‚É£ Indexing & Slicing</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: tensor([-0.2834, -0.5340, -0.4740, -0.3780,  1.1992,  0.6316,  0.4599,  1.4253,\n",
      "        -0.4524,  0.9431,  0.2878, -0.3138])\n",
      "\n",
      "a[0:1]: tensor([-0.2834])\n",
      "\n",
      "a[0]: -0.2833613455295563\n",
      "\n",
      "a[[0, 2, 7]]: tensor([-0.2834, -0.4740,  1.4253])\n"
     ]
    }
   ],
   "source": [
    "# Create a 1D tensor with 12 random values from a standard normal distribution (mean=0, std=1)\n",
    "a = torch.randn(12)\n",
    "print(f\"a: {a}\")\n",
    "print(f\"\\na[0:1]: {a[0:1]}\") # A slice of the tensor containing the first element (as a 1D tensor)\n",
    "print(f\"\\na[0]: {a[0]}\")     # The first element of the tensor (as a scalar)\n",
    "print(f\"\\na[[0, 2, 7]]: {a[[0, 2, 7]]}\") # A tensor containing the elements at indices 0, 2, and 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.2250,  0.0614, -1.3685,  0.1342, -1.5436]),\n",
       " tensor([ 0.2250,  0.0614, -1.3685,  0.1342, -1.5436]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `a[2:12:2]`: Slice the tensor from index 2 to index 12 (exclusive) with a step of 2\n",
    "# `a[2::2]`: Slice the tensor from index 2 to the end with a step of 2\n",
    "a[2:12:2], a[2::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:\n",
      "tensor([[-0.1248, -0.0112,  1.7749,  0.1002,  1.0930],\n",
      "        [ 0.6211,  0.3059, -0.9071, -1.0935, -0.5858],\n",
      "        [-1.2401,  0.9980,  0.6931, -1.2044, -0.0793]])\n",
      "\n",
      "a[0:3, 2:-1]:\n",
      "tensor([[ 1.7749,  0.1002],\n",
      "        [-0.9071, -1.0935],\n",
      "        [ 0.6931, -1.2044]])\n",
      "\n",
      "a[:, 2:-1]:\n",
      "tensor([[ 1.7749,  0.1002],\n",
      "        [-0.9071, -1.0935],\n",
      "        [ 0.6931, -1.2044]])\n"
     ]
    }
   ],
   "source": [
    "# Create a 2D tensor with random values from a standard normal distribution (mean=0, std=1)\n",
    "a = torch.randn(3, 5) # The tensor has a shape of (3, 5), meaning 3 rows and 5 columns\n",
    "print(f\"a:\\n{a}\")\n",
    "\n",
    "print(f\"\\na[0:3, 2:-1]:\\n{a[0:3, 2:-1]}\") # Slice rows from 0 to 3 (exclusive) and columns from 2 to -1 (exclusive)\n",
    "\n",
    "print(f\"\\na[:, 2:-1]:\\n{a[:, 2:-1]}\") # Slice all rows and columns from 2 to -1 (exclusive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:\n",
      "tensor([[-0.1248, -0.0112,  1.7749,  0.1002,  1.0930],\n",
      "        [ 0.6211,  0.3059, -0.9071, -1.0935, -0.5858],\n",
      "        [-1.2401,  0.9980,  0.6931, -1.2044, -0.0793]])\n",
      "\n",
      "a[0:2]:\n",
      "tensor([[-0.1248, -0.0112,  1.7749,  0.1002,  1.0930],\n",
      "        [ 0.6211,  0.3059, -0.9071, -1.0935, -0.5858]])\n",
      "\n",
      "a[0:2, :]:\n",
      "tensor([[-0.1248, -0.0112,  1.7749,  0.1002,  1.0930],\n",
      "        [ 0.6211,  0.3059, -0.9071, -1.0935, -0.5858]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"a:\\n{a}\")\n",
    "print(f\"\\na[0:2]:\\n{a[0:2]}\") # Slice rows from 0 to 2 (exclusive)\n",
    "print(f\"\\na[0:2, :]:\\n{a[0:2, :]}\") # Slice rows from 0 to 2 (exclusive) and all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:\n",
      "tensor([[-0.1248, -0.0112,  1.7749,  0.1002,  1.0930],\n",
      "        [ 0.6211,  0.3059, -0.9071, -1.0935, -0.5858],\n",
      "        [-1.2401,  0.9980,  0.6931, -1.2044, -0.0793]])\n",
      "\n",
      "a[::2, 2:]:\n",
      "tensor([[ 1.7749,  0.1002,  1.0930],\n",
      "        [ 0.6931, -1.2044, -0.0793]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"a:\\n{a}\")\n",
    "print(f\"\\na[::2, 2:]:\\n{a[::2, 2:]}\") # Slice rows with a step of 2 and columns from index 2 to the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a shape: torch.Size([4, 6, 7])\n",
      "\n",
      "a[1:2, 3:5, 2:4]:\n",
      "tensor([[[-1.0256, -1.5801],\n",
      "         [-0.3691, -0.5744]]])\n",
      "\n",
      "a[[1], 3:5, 2:4]:\n",
      "tensor([[[-1.0256, -1.5801],\n",
      "         [-0.3691, -0.5744]]])\n",
      "\n",
      "a[1, 3:5, 2:4]:\n",
      "tensor([[-1.0256, -1.5801],\n",
      "        [-0.3691, -0.5744]])\n"
     ]
    }
   ],
   "source": [
    "# Create a 3D tensor with random values from a standard normal distribution (mean=0, std=1)\n",
    "# The tensor has a shape of (4, 6, 7), meaning:4 matrices (depth/channels); Each matrix has 6 rows and 7 columns\n",
    "a = torch.randn(4, 6, 7)\n",
    "print(f\"a shape: {a.shape}\")\n",
    "print(f\"\\na[1:2, 3:5, 2:4]:\\n{a[1:2, 3:5, 2:4]}\") # Slice along all three dimensions\n",
    "print(f\"\\na[[1], 3:5, 2:4]:\\n{a[[1], 3:5, 2:4]}\") # Slice using a list for the first dimension\n",
    "print(f\"\\na[1, 3:5, 2:4]:\\n{a[1, 3:5, 2:4]}\") # Slice the first dimension using a single index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a shape: torch.Size([4, 6, 7])\n",
      "\n",
      "a[1]:\n",
      "tensor([[ 0.2711,  0.5925, -1.0946, -1.2273, -0.5208,  0.3546, -0.3520],\n",
      "        [ 1.5682,  0.2059,  0.9340,  2.5062,  0.3773, -0.3898, -0.9249],\n",
      "        [ 0.5543, -0.5919,  0.4789, -0.1221,  0.0417, -0.3066, -0.2064],\n",
      "        [-2.1017, -0.1180, -1.0256, -1.5801,  0.4127,  1.2566,  0.2430],\n",
      "        [ 0.3731, -1.0419, -0.3691, -0.5744, -0.6895, -0.9635,  1.6987],\n",
      "        [ 0.1723,  0.5141, -0.2876,  0.4528,  0.6898,  0.8877, -0.1313]])\n",
      "\n",
      "a[:, :, -1]:\n",
      "tensor([[ 0.5198,  0.6533, -1.0583,  0.4860, -0.6923, -0.4402],\n",
      "        [-0.3520, -0.9249, -0.2064,  0.2430,  1.6987, -0.1313],\n",
      "        [ 0.2777, -0.1732,  0.1644,  1.6397,  0.5564,  0.6767],\n",
      "        [-1.6913,  0.6657,  0.7359, -0.6686,  1.0609,  0.0662]])\n",
      "\n",
      "a[..., -1]:\n",
      "tensor([[ 0.5198,  0.6533, -1.0583,  0.4860, -0.6923, -0.4402],\n",
      "        [-0.3520, -0.9249, -0.2064,  0.2430,  1.6987, -0.1313],\n",
      "        [ 0.2777, -0.1732,  0.1644,  1.6397,  0.5564,  0.6767],\n",
      "        [-1.6913,  0.6657,  0.7359, -0.6686,  1.0609,  0.0662]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"a shape: {a.shape}\")\n",
    "print(f\"\\na[1]:\\n{a[1]}\") # Select the second matrix (index 1) along the first dimension\n",
    "print(f\"\\na[:, :, -1]:\\n{a[:, :, -1]}\") # Select the last column from all matrices and all rows\n",
    "print(f\"\\na[..., -1]:\\n{a[..., -1]}\") # Same as above, using `...` (ellipsis) to represent all dimensions except the last"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#aaff5499\" size=\"4.5\" face=\"Arial\"><b>8Ô∏è‚É£ Unsqueeze & squeeze</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape of tensor_a: torch.Size([1, 3, 1, 4, 1])\n",
      "Squeezed shape of tensor_b: torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "torch.squeeze(input, dim=None)\n",
    "torch.unsqueeze(input, dim)\n",
    "\"\"\"\n",
    "# Create a tensor with singleton dimensions (dimensions of size 1)\n",
    "# The tensor has a shape of (1, 3, 1, 4, 1), meaning:\n",
    "# - 1 matrix (depth/channels)\n",
    "# - 3 rows\n",
    "# - 1 column\n",
    "# - 4 channels\n",
    "# - 1 additional singleton dimension\n",
    "tensor_a = torch.randn(1, 3, 1, 4, 1)\n",
    "print(\"Original shape of tensor_a:\", tensor_a.shape)\n",
    "\n",
    "# Remove all singleton dimensions using the `squeeze()` method (This eliminates dimensions of size 1)\n",
    "tensor_b = tensor_a.squeeze()\n",
    "print(\"Squeezed shape of tensor_b:\", tensor_b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape of a: torch.Size([2, 1, 3, 1, 4])\n",
      "a.squeeze(0).shape = torch.Size([2, 1, 3, 1, 4])\n",
      "a.squeeze(1).shape = torch.Size([2, 3, 1, 4])\n",
      "a.squeeze(3).shape = torch.Size([2, 1, 3, 4])\n",
      "a.squeeze().shape = torch.Size([2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "# Removing a specific singleton dimension\n",
    "a = torch.randn(2, 1, 3, 1, 4)\n",
    "print(\"Original shape of a:\", a.shape)  # Output: torch.Size([2, 1, 3, 1, 4])\n",
    "\n",
    "# Remove the first dimension (index 0) which is not 1, so no change is done; Output: torch.Size([2, 1, 3, 1, 4])\n",
    "print(f\"{a.squeeze(0).shape = }\")\n",
    "\n",
    "# Remove the second dimension (index 1) which is size 1; Output: torch.Size([2, 3, 1, 4])\n",
    "print(f\"{a.squeeze(1).shape = }\")\n",
    "\n",
    "# Remove the fourth dimension (index 3) which is size 1; Output: torch.Size([2, 1, 3, 4])\n",
    "print(f\"{a.squeeze(3).shape = }\")\n",
    "\n",
    "print(f\"{a.squeeze().shape = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: tensor([[-2.1785, -0.5201],\n",
      "        [ 1.0294,  1.8954]])\n",
      "\n",
      "b.unsqueeze(0) = tensor([[[-2.1785, -0.5201],\n",
      "         [ 1.0294,  1.8954]]]) --> b.unsqueeze(0).shape = torch.Size([1, 2, 2])\n",
      "\n",
      "b.unsqueeze(1) = tensor([[[-2.1785, -0.5201]],\n",
      "\n",
      "        [[ 1.0294,  1.8954]]]) --> b.unsqueeze(1).shape = torch.Size([2, 1, 2])\n",
      "\n",
      "b.unsqueeze(2) = tensor([[[-2.1785],\n",
      "         [-0.5201]],\n",
      "\n",
      "        [[ 1.0294],\n",
      "         [ 1.8954]]]) --> b.unsqueeze(2).shape = torch.Size([2, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "b = torch.randn(2, 2)\n",
    "print(\"Original:\", b)  # Output: torch.Size([3, 4])\n",
    "\n",
    "# Add dimension at the beginning (index 0); # Output: torch.Size([1, 3, 4])\n",
    "print(f\"\\n{b.unsqueeze(0) = } --> {b.unsqueeze(0).shape = }\")\n",
    "# Add dimension in between the two dimensions (index 1); Output: torch.Size([3, 1, 4])\n",
    "print(f\"\\n{b.unsqueeze(1) = } --> {b.unsqueeze(1).shape = }\")\n",
    "\n",
    "# Add dimension at the end (index 2); Output: torch.Size([3, 4, 1])\n",
    "print(f\"\\n{b.unsqueeze(2) = } --> {b.unsqueeze(2).shape = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='#hh99gg99' size='4.5' face=\"Arial\"><b>üîü PyTorch tensors & NumPy</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array: [1. 2. 3. 4. 5. 6. 7.]\n",
      "tensor: tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64)\n",
      "nump: [1. 2. 3. 4. 5. 6. 7.]\n"
     ]
    }
   ],
   "source": [
    "array = np.arange(1.0, 8.0) # Create a NumPy array with values ranging from 1.0 to 8.0 (exclusive)\n",
    "tensor = torch.from_numpy(array) # Convert the NumPy array to a PyTorch tensor\n",
    "nump = torch.Tensor.numpy(tensor) # Convert the PyTorch tensor back to a NumPy array\n",
    "print(f\"array: {array}\")\n",
    "print(f\"tensor: {tensor}\")\n",
    "print(f\"nump: {nump}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=#e5e90b size='4.5' face=\"Arial\"><b>üîü Array Manipulation**</b></font><br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked:\n",
      " tensor([[[ 0.1466, -1.0041],\n",
      "         [-0.7882, -0.8074]],\n",
      "\n",
      "        [[-0.2957, -0.1462],\n",
      "         [ 0.3641,  0.4331]]])\n"
     ]
    }
   ],
   "source": [
    "# ================================================ Stack =======================================================\n",
    "\"\"\"\n",
    "torch.stack(tensors, dim=0)\n",
    "torch.cat(tensors, dim=0)\n",
    "\"\"\"\n",
    "# Create a 2D tensor\n",
    "a = torch.randn(2, 2)\n",
    "b = torch.randn(2, 2)\n",
    "# Stack vertically (along a new dimension)\n",
    "stacked = torch.stack((a, b), dim=0)\n",
    "print(\"Stacked:\\n\", stacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Concatenated:\n",
      " tensor([[[ 0.1466, -1.0041],\n",
      "         [-0.7882, -0.8074],\n",
      "         [-0.2957, -0.1462],\n",
      "         [ 0.3641,  0.4331]]])\n"
     ]
    }
   ],
   "source": [
    "# ================================================= Cat ========================================================\n",
    "# Concatenate horizontally (along an existing dimension)\n",
    "concatenated = torch.cat((a.unsqueeze(0), b.unsqueeze(0)), dim=1)\n",
    "print(\"\\nConcatenated:\\n\", concatenated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " a = tensor([[ 1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12]])\n",
      "\n",
      " torch.split(a, 2, dim=1) = (tensor([[ 1,  2],\n",
      "        [ 5,  6],\n",
      "        [ 9, 10]]), tensor([[ 3,  4],\n",
      "        [ 7,  8],\n",
      "        [11, 12]]))\n",
      "\n",
      " torch.split(a, 3, dim=0) = (tensor([[ 1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12]]),)\n"
     ]
    }
   ],
   "source": [
    "# =============================================== Split ========================================================\n",
    "\"\"\"\n",
    "torch.split(tensor, split_size_or_sections, dim=0)\n",
    "split_size_or_sections:\n",
    "If an integer, the tensor is split into chunks of size split_size along dim.\n",
    "If a list of integers, the tensor is split into sections of the specified sizes.\n",
    "\"\"\"\n",
    "# Create a 2D tensor\n",
    "a = torch.arange(1, 13).reshape(3, 4)\n",
    "print(f\"\\n {a = }\")\n",
    "\n",
    "# Perform horizontal splitting of tensor 'a' into 2 equal parts\n",
    "print(f\"\\n {torch.split(a, 2, dim=1) = }\")  # horizontal splitting --> 2 means split 2D tensor into 2 equal parts along columns\n",
    "\n",
    "# Perform vertical splitting of tensor 'a' into 3 equal parts\n",
    "print(f\"\\n {torch.split(a, 3, dim=0) = }\")  # vertical splitting --> 3 means split 2D tensor into 3 equal parts along rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split tensors: (tensor([1, 2, 3]), tensor([4, 5, 6]))\n"
     ]
    }
   ],
   "source": [
    "# Split a tensor into 2 equal parts\n",
    "tensor = torch.tensor([1, 2, 3, 4, 5, 6])\n",
    "split_tensors = torch.split(tensor, 3)\n",
    "print(\"Split tensors:\", split_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " a = tensor([[[ 1,  2,  3,  4],\n",
      "         [ 5,  6,  7,  8]],\n",
      "\n",
      "        [[ 9, 10, 11, 12],\n",
      "         [13, 14, 15, 16]],\n",
      "\n",
      "        [[17, 18, 19, 20],\n",
      "         [21, 22, 23, 24]]]) , a.shape = torch.Size([3, 2, 4])\n",
      "\n",
      " a.flatten() = tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
      "        19, 20, 21, 22, 23, 24])\n",
      "\n",
      " a.reshape(-1) = tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
      "        19, 20, 21, 22, 23, 24])\n",
      "\n",
      " a.flatten()[4] = tensor(5)\n"
     ]
    }
   ],
   "source": [
    "# ========================================== Flatten & ravel ===================================================\n",
    "\"\"\"flattened_tensor = torch.flatten(input, start_dim=0, end_dim=-1)\"\"\"\n",
    "# Create a 3D tensor\n",
    "a = torch.arange(1, 25).reshape(3, 2, 4)\n",
    "print(f\"\\n {a = } , {a.shape = }\")\n",
    "\n",
    "# Flatten the tensor into a 1D tensor\n",
    "print(f\"\\n {a.flatten() = }\")  # Flatten the tensor into a 1D tensor\n",
    "\n",
    "'''For `ravel`, since PyTorch doesn't have a `ravel` method, using `view(-1)` or `reshape(-1)` would give a flattened\n",
    "tensor, Use reshape to achieve ravel-like behavior.'''\n",
    "\n",
    "print(f\"\\n {a.reshape(-1) = }\")  # Equivalent to ravel in NumPy\n",
    "\n",
    "# Access the 5th element of the flattened tensor\n",
    "print(f\"\\n {a.flatten()[4] = }\")  # Access the 5th element of the flattened tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor:\n",
      "tensor([[[1, 2],\n",
      "         [3, 4]],\n",
      "\n",
      "        [[5, 6],\n",
      "         [7, 8]]])\n",
      "\n",
      "Fullyflattened tensor: tensor([1, 2, 3, 4, 5, 6, 7, 8])\n",
      "\n",
      "Partially flattened tensor:\n",
      " tensor([[1, 2, 3, 4],\n",
      "        [5, 6, 7, 8]])\n"
     ]
    }
   ],
   "source": [
    "# Define a 3D tensor with shape (2, 2, 2)\n",
    "tensor = torch.tensor([[[1, 2], \n",
    "                        [3, 4]], \n",
    "                          \n",
    "                       [[5, 6], \n",
    "                        [7, 8]]])\n",
    "print(f\"Original tensor:\\n{tensor}\")\n",
    "\n",
    "# Flatten the tensor starting from dimension 0 (flattens the entire tensor into a 1D array)\n",
    "flattened_partial = torch.flatten(tensor, start_dim=0)  \n",
    "print(\"\\nFullyflattened tensor:\", flattened_partial)\n",
    "\n",
    "# Flatten the tensor starting from dimension 1 (flattens each 2x2 matrix into a 1D array, keeping the outer dimension)\n",
    "flattened_partial = torch.flatten(tensor, start_dim=1)\n",
    "\n",
    "# Print the partially flattened tensor (each 2x2 matrix is flattened, but the outer structure remains)\n",
    "print(\"\\nPartially flattened tensor:\\n\", flattened_partial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor:\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "\n",
      "Cloned tensor:\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "\n",
      "Modified cloned tensor:\n",
      "tensor([[99,  2,  3],\n",
      "        [ 4,  5,  6]])\n",
      "\n",
      "Original tensor after modification:\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "# ======================================== Clone (copy & deepcopy) =============================================\n",
    "\"\"\"cloned_tensor = tensor.clone()\"\"\"\n",
    "# Create a 2D tensor \n",
    "tensor = torch.tensor([[1, 2, 3], \n",
    "                       [4, 5, 6]])\n",
    "print(f\"Original tensor:\\n{tensor}\")\n",
    "\n",
    "# Clone the tensor\n",
    "cloned_tensor = tensor.clone()\n",
    "print(f\"\\nCloned tensor:\\n{cloned_tensor}\")\n",
    "\n",
    "# Modify the cloned tensor\n",
    "cloned_tensor[0, 0] = 99\n",
    "print(f\"\\nModified cloned tensor:\\n{cloned_tensor}\")\n",
    "print(f\"\\nOriginal tensor after modification:\\n{tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tensor: tensor([1, 2, 3])\n",
      "tensor.repeat(2) = tensor([1, 2, 3, 1, 2, 3])\n",
      "\n",
      "Original Tensor:\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "\n",
      "Repeated:\n",
      "tensor([[1, 2, 1, 2, 1, 2],\n",
      "        [3, 4, 3, 4, 3, 4],\n",
      "        [1, 2, 1, 2, 1, 2],\n",
      "        [3, 4, 3, 4, 3, 4]])\n"
     ]
    }
   ],
   "source": [
    "# ================================================ Repeat ======================================================\n",
    "\"\"\"\n",
    "repeated_tensor = tensor.repeat(*sizes)\n",
    "*sizes: A sequence of integers specifying how many times to repeat the tensor along each dimension.\n",
    "\"\"\"\n",
    "# Create a 1D tensor \n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "print(f\"Original Tensor: {tensor}\")\n",
    "repeated = tensor.repeat(2)  # Repeat twice along the first (only) dimension\n",
    "print(f\"{tensor.repeat(2) = }\")  # Output: tensor([1, 2, 3, 1, 2, 3])\n",
    "\n",
    "# Create a 2D tensor \n",
    "tensor = torch.tensor([[1, 2], \n",
    "                       [3, 4]])\n",
    "print(f\"\\nOriginal Tensor:\\n{tensor}\")\n",
    "repeated = tensor.repeat(2, 3)  # Repeat 2x along rows, 3x along columns\n",
    "print(f\"\\nRepeated:\\n{tensor.repeat(2, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 1, 2, 1, 2, 1, 2],\n",
       "         [1, 2, 1, 2, 1, 2, 1, 2],\n",
       "         [1, 2, 1, 2, 1, 2, 1, 2]],\n",
       "\n",
       "        [[1, 2, 1, 2, 1, 2, 1, 2],\n",
       "         [1, 2, 1, 2, 1, 2, 1, 2],\n",
       "         [1, 2, 1, 2, 1, 2, 1, 2]]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor([[[1, 2]]])  # Shape: (1, 1, 2)\n",
    "repeated = tensor.repeat(2, 3, 4)  # Repeat 2x (dim 0), 3x (dim 1), 4x (dim 2)\n",
    "print(repeated.shape)  # Output: torch.Size([2, 3, 8])\n",
    "repeated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tensor: tensor([1, 2])\n",
      "tiled = tensor([1, 2, 1, 2])\n",
      "\n",
      "Original Tensor_2d:\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "tiled = tensor([[1, 2, 1, 2, 1, 2],\n",
      "        [1, 2, 1, 2, 1, 2]])\n",
      "\n",
      "Original Tensor_3d:\n",
      "tensor([[[1, 2]]])\n",
      "\n",
      "tiled.shape = torch.Size([2, 3, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 1, 2, 1, 2, 1, 2],\n",
       "         [1, 2, 1, 2, 1, 2, 1, 2],\n",
       "         [1, 2, 1, 2, 1, 2, 1, 2]],\n",
       "\n",
       "        [[1, 2, 1, 2, 1, 2, 1, 2],\n",
       "         [1, 2, 1, 2, 1, 2, 1, 2],\n",
       "         [1, 2, 1, 2, 1, 2, 1, 2]]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ====================================================== Tile ==================================================\n",
    "\"\"\"tiled_tensor = torch.tile(input, reps)\"\"\"\n",
    "# Create a 1D tensor \n",
    "tensor = torch.tensor([1, 2]) \n",
    "print(f\"Original Tensor: {tensor}\")\n",
    "tiled = torch.tile(tensor, (2,))  # Repeat twice along the first dimension\n",
    "print(f\"{tiled = }\")  # Output: tensor([1, 2, 1, 2])\n",
    "\n",
    "# Create a 2D tensor \n",
    "tensor_2d = torch.tensor([[1, 2], \n",
    "                          [3, 4]]) \n",
    "print(f\"\\nOriginal Tensor_2d:\\n{tensor_2d}\")\n",
    "# Repeat 2x along rows (dim=0) and 3x along columns (dim=1)\n",
    "tiled = torch.tile(tensor, (2, 3))\n",
    "print(f\"{tiled = }\")\n",
    "\n",
    "tensor = torch.tensor([[[1, 2]]])  # Shape: (1, 1, 2)\n",
    "print(f\"\\nOriginal Tensor_3d:\\n{tensor}\")\n",
    "tiled = torch.tile(tensor, (2, 3, 4))  # Repeat 2x (dim=0), 3x (dim=1), 4x (dim=2)\n",
    "print(f\"\\n{tiled.shape = }\")  # Output: torch.Size([2, 3, 8])\n",
    "tiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tensor: tensor([2, 1, 3, 2, 1])\n",
      "\n",
      "unique_elements: tensor([1, 2, 3])\n",
      "\n",
      "Inverse Indices: tensor([1, 0, 2, 1, 0])\n",
      "\n",
      "reconstructed: tensor([2, 1, 3, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "# ================================================ Unique ======================================================\n",
    "\"\"\"\n",
    "sorted_tensor, sorted_indices = torch.unique(tensor \n",
    "                        sorted=True,          # Return sorted unique values (default: True)\n",
    "                        return_inverse=False, # Return indices to reconstruct original tensor from unique values\n",
    "                        return_counts=False,  # Return counts of each unique element\n",
    "                        dim=None              # Dimension to apply \"unique\" on (for multi-dimensional tensors)\n",
    ")\n",
    "\"\"\"\n",
    "# Create a tensor with duplicate values\n",
    "tensor = torch.tensor([2, 1, 3, 2, 1])\n",
    "print(f\"Original Tensor: {tensor}\")\n",
    "\n",
    "# Get unique elements and inverse indices\n",
    "unique_elements, inverse_indices = torch.unique(tensor, return_inverse=True)\n",
    "print(f\"\\nunique_elements: {unique_elements}\")  # Output: tensor([1, 2, 3])\n",
    "print(f\"\\nInverse Indices: {inverse_indices}\")  # tensor([1, 0, 2, 1, 0])\n",
    "\n",
    "# Reconstruct the original tensor from unique values:\n",
    "reconstructed = unique_elements[inverse_indices]\n",
    "print(f\"\\nreconstructed: {reconstructed}\")  # Output: tensor([2, 1, 3, 2, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique: tensor([1, 2, 3])\n",
      "Counts: tensor([2, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "# Get unique elements and their counts\n",
    "unique_elements, counts = torch.unique(tensor, return_counts=True)\n",
    "print(\"Unique:\", unique_elements)    # tensor([1, 2, 3])\n",
    "print(\"Counts:\", counts)    # tensor([2, 2, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tensor:\n",
      " tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [1, 2]])\n",
      "\n",
      "Unique rows:\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "\n",
      "Unique columns:\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "# Create a 2D tensor with duplicate rows\n",
    "tensor_2d = torch.tensor([[1, 2], \n",
    "                          [3, 4], \n",
    "                          [1, 2]])\n",
    "print(f\"Original Tensor:\\n {tensor_2d}\")\n",
    "\n",
    "# Find unique rows (dim=0)\n",
    "unique_rows = torch.unique(tensor_2d, dim=0)\n",
    "print(f\"\\nUnique rows:\\n{unique_rows}\")\n",
    "# Output: tensor([[1, 2], [3, 4]])\n",
    "\n",
    "# Find unique columns (dim=1)\n",
    "tensor_2d_col = torch.tensor([[1, 2, 1], \n",
    "                              [3, 4, 3]])\n",
    "unique_cols = torch.unique(tensor_2d_col, dim=1)\n",
    "print(f\"\\nUnique columns:\\n{unique_cols}\")\n",
    "# Output: tensor([[1, 2], [3, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tensor: tensor([3., 1., 4., nan, 2., 5.])\n",
      "\n",
      "Sorted values: tensor([1., 2., 3., 4., 5., nan])\n",
      "Sorted indices: tensor([1, 4, 0, 2, 5, 3])\n",
      "\n",
      "Sorted rows:\n",
      " tensor([[1, 3],\n",
      "        [2, 4],\n",
      "        [0, 5]])\n",
      "\n",
      "BB('height','age'):\n",
      "[('Q', 1.7, 38), ('A', 1.8, 41), ('R', 1.9, 38)]\n"
     ]
    }
   ],
   "source": [
    "# ================================================== Sort ======================================================\n",
    "\"\"\"\n",
    "sorted_tensor, sorted_indices = torch.sort(tensor, \n",
    "                                           dim=-1,          # Dimension to sort along (default: last dimension)\n",
    "                                           descending=False # Sort in ascending (False) or descending (True) order\n",
    ")\n",
    "\"\"\"\n",
    "# Create a 1D tensor \n",
    "tensor = torch.tensor([3, 1, 4, float('nan'), 2, 5])\n",
    "print(f\"Original Tensor: {tensor}\")\n",
    "\n",
    "sorted_values, sorted_indices = torch.sort(tensor) # PyTorch sorts NaN values to the end by default\n",
    "print(f\"\\nSorted values: {sorted_values}\")    # tensor([1, 2, 3, 4, 5])\n",
    "print(f\"Sorted indices: {sorted_indices}\")    # tensor([1, 3, 0, 2, 4])\n",
    "\n",
    "# Create a 2D tensor (sort rows)\n",
    "tensor_2d = torch.tensor([[3, 1], \n",
    "                          [4, 2], \n",
    "                          [5, 0]])\n",
    "sorted_rows, row_indices = torch.sort(tensor_2d, dim=1)\n",
    "print(\"\\nSorted rows:\\n\", sorted_rows)\n",
    "\n",
    "# Structured arrays are not directly supported in PyTorch, so we use a list of tuples\n",
    "# Create a list of tuples with fields 'name', 'height', and 'age'\n",
    "values = [('A', 1.8, 41), ('R', 1.9, 38), ('Q', 1.7, 38)]\n",
    "\n",
    "# Sort the list of tuples first by 'height' and then by 'age'\n",
    "BB = sorted(values, key=lambda x: (x[1], x[2]))\n",
    "print(f\"\\nBB('height','age'):\\n{BB}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tensor: tensor([3, 1, 4, 2, 5])\n",
      "Argsort indices:tensor([1, 3, 0, 2, 4])\n",
      "\n",
      "Original Tensor:\n",
      "tensor([[3, 1],\n",
      "        [4, 2],\n",
      "        [5, 0]])\n",
      "\n",
      "Argsort indices:\n",
      "tensor([[1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0]])\n"
     ]
    }
   ],
   "source": [
    "# =================================================== Argsort ==================================================\n",
    "\"\"\"\n",
    "indices = torch.argsort(tensor,\n",
    "                        dim=-1,          # Dimension to sort along\n",
    "                        descending=False\n",
    ")\n",
    "\"\"\"\n",
    "# Create a 1D tensor \n",
    "tensor = torch.tensor([3, 1, 4, 2, 5])\n",
    "print(f\"Original Tensor: {tensor}\")\n",
    "\n",
    "# Get indices to sort a tensor\n",
    "indices = torch.argsort(tensor, descending=False)\n",
    "print(f\"Argsort indices:{indices}\")\n",
    "\n",
    "# Create a 2D tensor (sort rows)\n",
    "tensor_2d = torch.tensor([[3, 1], \n",
    "                          [4, 2], \n",
    "                          [5, 0]])\n",
    "print(f\"\\nOriginal Tensor:\\n{tensor_2d}\")\n",
    "\n",
    "# Get indices to sort a tensor\n",
    "indices = torch.argsort(tensor_2d, descending=False)\n",
    "print(f\"\\nArgsort indices:\\n{indices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_idx = tensor(4)\n",
      "tensor([2, 1])\n",
      "tensor([0, 0, 0])\n",
      "tensor(4)\n"
     ]
    }
   ],
   "source": [
    "# ================================================= Argmax =====================================================\n",
    "\"\"\"\n",
    "torch.argmax(tensor, \n",
    "             dim=None,     # Dimension to reduce (if `None`, returns index of max in flattened tensor)\n",
    "             keepdim=False # Whether to retain the reduced dimension in the output\n",
    ")\n",
    "\"\"\"\n",
    "# Create a 1D tensor \n",
    "tensor = torch.tensor([3, 1, 4, 2, 5])\n",
    "max_idx = torch.argmax(tensor)\n",
    "print(f\"{max_idx = }\")  # Output: tensor(4) (index of 5)\n",
    "\n",
    "# Create a 2D tensor \n",
    "tensor_2d = torch.tensor([[3, 1], \n",
    "                          [4, 2], \n",
    "                          [5, 0]])\n",
    "\n",
    "# Along rows (dim=0)\n",
    "max_idx_dim0 = torch.argmax(tensor_2d, dim=0)\n",
    "print(max_idx_dim0)  # Output: tensor([2, 0]) (indices: [5, 1])\n",
    "\n",
    "# Along columns (dim=1)\n",
    "max_idx_dim1 = torch.argmax(tensor_2d, dim=1)\n",
    "print(max_idx_dim1)  # Output: tensor([0, 0, 0]) (indices: 3, 4, 5)\n",
    "\n",
    "# Without specifying `dim` (flattens the tensor)\n",
    "max_idx_flat = torch.argmax(tensor_2d)\n",
    "print(max_idx_flat)  # Output: tensor(4) (index of 5 in flattened tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1)\n",
      "tensor([0, 2])\n",
      "tensor([1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# ================================================== Argmin ====================================================\n",
    "\"\"\"\n",
    "torch.argmin(tensor, \n",
    "             dim=None,     # Dimension to reduce\n",
    "             keepdim=False \n",
    ")\n",
    "\"\"\"\n",
    "# Create a 1D tensor \n",
    "tensor_1d = torch.tensor([3, 1, 4, 2, 5])\n",
    "min_idx_1d = torch.argmin(tensor_1d)\n",
    "print(min_idx_1d)  # Output: tensor(1) (index of 1)\n",
    "\n",
    "# Create a 2D tensor \n",
    "tensor_2d = torch.tensor([[3, 1], \n",
    "                          [4, 2], \n",
    "                          [5, 0]])\n",
    "\n",
    "# Along rows (dim=0)\n",
    "min_idx_dim0 = torch.argmin(tensor_2d, dim=0)\n",
    "print(min_idx_dim0)  # Output: tensor([0, 2]) (indices: [3, 0])\n",
    "\n",
    "# Along columns (dim=1)\n",
    "min_idx_dim1 = torch.argmin(tensor_2d, dim=1)\n",
    "print(min_idx_dim1)  # Output: tensor([1, 1, 1]) (indices: 1, 2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  1,   2,   3,   4],\n",
      "        [  9,   7,  11, -20],\n",
      "        [  9,  -7,  12,   6]])\n",
      "\n",
      "A((A>=3) & (A<10), A, -10):\n",
      " tensor([[-10, -10,   3,   4],\n",
      "        [  9,   7, -10, -10],\n",
      "        [  9, -10, -10,   6]])\n",
      "\n",
      "torch.argwhere:\n",
      "tensor([[0, 0],\n",
      "        [0, 1],\n",
      "        [0, 2],\n",
      "        [0, 3],\n",
      "        [1, 0],\n",
      "        [1, 1],\n",
      "        [1, 2],\n",
      "        [2, 0],\n",
      "        [2, 2],\n",
      "        [2, 3]])\n",
      "\n",
      " tensor[tensor > 7] = tensor([ 9, 11,  9, 12])\n"
     ]
    }
   ],
   "source": [
    "# ====================================== Where, argwhere, & extract ============================================\n",
    "\"\"\"\n",
    "torch.where(condition, x, y)\n",
    "torch.nonzero(condition, as_tuple=False)\n",
    "tensor[condition]\n",
    "\"\"\"\n",
    "# Create a 2D tensor\n",
    "tensor = torch.tensor([[1, 2, 3, 4], \n",
    "                       [9, 7, 11, -20], \n",
    "                       [9, -7, 12, 6]])\n",
    "print(f\"{tensor}\")\n",
    "\n",
    "# If the condition (A >= 3) & (A < 10) is True, keep the original value; otherwise, replace with -10\n",
    "AA = torch.where((tensor >= 3) & (tensor < 10), tensor, torch.tensor(-10))\n",
    "print(f\"\\nA((A>=3) & (A<10), A, -10):\\n {AA}\")\n",
    "\n",
    "# torch.argwhere (using torch.nonzero)\n",
    "indices = torch.nonzero(tensor > 0)  # Find indices of elements > 0\n",
    "print(f\"\\ntorch.argwhere:\\n{indices}\")  \n",
    "\n",
    "# Extract (using boolean indexing) ‚Üí tensor[condition]\n",
    "B = tensor[tensor > 7]\n",
    "print(f\"\\n {tensor[tensor > 7] = }\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
