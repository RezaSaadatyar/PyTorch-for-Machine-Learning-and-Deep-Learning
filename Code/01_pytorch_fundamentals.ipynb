{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Presented by: Reza Saadatyar (2024-2025)**<br/>\n",
    "**E-mail: Reza.Saadatyar@outlook.com**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1Ô∏è‚É£ CPU (Central Processing Unit) & GPU (Graphics Processing Unit)**\n",
    "- `CPU`\n",
    "  - Designed for general-purpose computing.\n",
    "  - Optimized for sequential tasks.\n",
    "  - Has a few powerful cores.\n",
    "  - Excellent at handling complex logic and single-threaded applications.\n",
    "- `GPU`\n",
    "  - Designed for parallel processing.\n",
    "  - Has thousands of smaller, less powerful cores.\n",
    "  - GPUs offer far faster numerical computing than CPUs.\n",
    "  - Optimized for tasks that can be divided into many independent calculations.\n",
    "  - Excellent for tasks like matrix operations, which are common in deep learning.\n",
    "\n",
    "Putting a tensor on GPU using `to(device)` (e.g. `some_tensor.to(device)`) returns a copy of that tensor, e.g. the same tensor will be on CPU and GPU. `some_tensor = some_tensor.to(device)`  \n",
    "\n",
    "**2Ô∏è‚É£ N-d Tensor** A tensor is a multi-dimensional array of numerical values. Tensor computation (like numpy) with strong GPU acceleration.\n",
    "- `0-dimensional (Scalar):` A single number, e.g., 5, 3.14, -10. A <font color='red'><b>scalar</b></font> is a single number and in tensor-speak it's a zero dimension tensor.\n",
    "- `1-dimensional (Vector):` A list of numbers, e.g., [1, 2, 3]. A <font color='blue'><b>vector</b></font> is a single dimension tensor but can contain many numbers.<br/>\n",
    "- `2-dimensional (Matrix):` A table of numbers, e.g., [[1, 2], [3, 4]]. <font color='green'><b>MATRIX</b></font>  has two dimensions.\n",
    "- `3-dimensional (or higher):` Like a \"cube\" of numbers or more complex higher-dimensional structures. These are common for representing images, videos, and more.\n",
    "\n",
    "**3Ô∏è‚É£ Tensor datatypes**<br/>\n",
    "There are many different [tensor datatypes available in PyTorch](https://pytorch.org/docs/stable/tensors.html#data-types). Some are specific for CPU and some are better for GPU.<br/>\n",
    "Generally if you see `torch.cuda` anywhere, the tensor is being used for GPU (since Nvidia GPUs use a computing toolkit called CUDA).<br/>\n",
    "The most common type (and generally the default) is `torch.float32` or `torch.float`.<br/>\n",
    "\n",
    "**4Ô∏è‚É£ Getting information from tensors**<br/>\n",
    "* `shape` - what shape is the tensor? (some operations require specific shape rules)\n",
    "* `dtype` - what datatype are the elements within the tensor stored in?\n",
    "* `device` - what device is the tensor stored on? (usually GPU or CPU)\n",
    "\n",
    "**5Ô∏è‚É£ Math Operations**<br/>\n",
    "* Addition ‚áí `a+b `or `torh.add(a, b)`\n",
    "* Substraction ‚áí `a-b `or `torh.sub(a, b)`\n",
    "* Multiplication (element-wise) ‚áí `a*b `\n",
    "* Division ‚áí `a/b `or `torh.div(a, b)`\n",
    "* Matrix multiplication ‚áí \"`@`\" in Python is the symbol for matrix multiplication. [`torch.matmul()`](https://pytorch.org/docs/stable/generated/torch.matmul.html) or [`torch.mm()`](https://pytorch.org/docs/stable/generated/torch.mm.html)\n",
    "  \n",
    "**6Ô∏è‚É£ Special Arrays**<br/>\n",
    "- zeros\n",
    "- ones\n",
    "- empty\n",
    "- eye\n",
    "- full<br/>\n",
    "\n",
    "Using [`torch.zeros_like(input)`](https://pytorch.org/docs/stable/generated/torch.zeros_like.html) or [`torch.ones_like(input)`](https://pytorch.org/docs/1.9.1/generated/torch.ones_like.html) which return a tensor filled with zeros or ones in the same shape as the `input` respectively.\n",
    "\n",
    "**7Ô∏è‚É£ Random Arrays**\n",
    "- `torch.rand:` Create a n*m tensor filled with random numbers from a uniform distribution on the interval [0, 1)\n",
    "- `torch.randn:` Create a n*m tensor filled with random numbers from a normal distribution with mean 0 and variance 1. \n",
    "- `torch.randint:` Create a n*m tensor filled with random integers generated uniformly between low (inclusive) and high (exclusive).\n",
    "\n",
    "`torch.randperm(value):` Create a random permutation of integers from 0 to value.<br/>\n",
    "`torch.permute(input, dims):` Permute the original tensor to rearrange the axis order.\n",
    "\n",
    "**8Ô∏è‚É£ Indexing & Slicing**\n",
    "- `Indexing`\n",
    "  - Accessing individual elements:  use integer indices to specify the position of the element you want to retrieve.\n",
    "- `Slicing`\n",
    "  - Extracting sub-tensors: Slicing allows you to extract a sub-part of your tensor by specifying a range of indices using the colon : operator.\n",
    "    - `start:end` (exclusive end)\n",
    "    - `start:` (from start to end of dimension)\n",
    "    - `:end` (from beginning to end of dimension)\n",
    "    - `:` (all elements)\n",
    "    - `start:end:step` (start to end with given step)\n",
    "  - Slicing with steps: You can include a step to skip elements in the slice. `start:end:step`\n",
    "\n",
    "**9Ô∏è‚É£ Unsqueeze & unsqueeze**\n",
    "- The squeeze() method removes all singleton dimensions from a tensor. It will reduce the number of dimensions by removing the ones that have a size of 1.\n",
    "- The unsqueeze() method adds a singleton dimension at a specified position in a tensor. It will increase the number of dimensions by adding a size of 1 dimension at a specific position.\n",
    "\n",
    "**üîü PyTorch tensors & NumPy**\n",
    "- [`torch.from_numpy(ndarray)`](https://pytorch.org/docs/stable/generated/torch.from_numpy.html)  NumPy array ‚Üí PyTorch tensor\n",
    "- [`torch.Tensor.numpy()`](https://pytorch.org/docs/stable/generated/torch.Tensor.numpy.html)  PyTorch tensor ‚Üí NumPy array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='#FF000e' size=\"4.5\" face=\"Arial\"><b>Import modules</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch  #  torch.__version__  -> '2.5.1+cpu'\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='#00ff0e' size=\"4.5\" face=\"Arial\"><b>CPU vs GPU</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'nvidia-smi' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# To check if you've got access to a Nvidia GPU, you can run `!nvidia-smi` where the `!` (also called bang) means\n",
    "# \"run this on the command line\".\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.backends.mps.is_available() # Check for GPU on a Mac\n",
    "torch.cuda.is_available()           # Check for GPU on Wind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device = 'cpu', device_count = 0\n"
     ]
    }
   ],
   "source": [
    "# Set the device to 'cuda' (GPU) if a CUDA-compatible GPU is available, otherwise set it to 'cpu' (CPU)\n",
    "# This is commonly used in PyTorch to ensure computations are performed on the GPU for faster processing when available\n",
    "# device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"  # Set device type\n",
    "device_count =  torch.cuda.device_count()  # Count number of devices\n",
    "print(f\"{device = }, {device_count = }\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3]), array([1, 2, 3], dtype=int64))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Putting tensors (and models) on the GPU or CPU\n",
    "tensor = torch.tensor([1, 2, 3]) # Create tensor (default on CPU)\n",
    "tensor_on_gpu = tensor.to(device) # Move tensor to GPU (if available)\n",
    "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()  # Moving tensors back to the CPU using .cpu().numpy()\n",
    "tensor_on_gpu, tensor_back_on_cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<font color='#001240ee' size=\"4.5\" face=\"Arial\"><b>Scalar, Vector, Column vector, Matrix, & N-d Tensor</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.3333)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a 0-dimensional tensor (scalar) ‚Üí A 0D tensor represents a single value, similar to a scalar in mathematics\n",
    "torch.tensor(4/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = tensor([1, 2, 3]) --> a.__class__ = <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# Create a 1-dimensional tensor (vector) ‚Üí A 1D tensor is a list of values, similar to a vector in mathematics\n",
    "a = torch.tensor([1, 2, 3])\n",
    "print(f\"{a = } --> {a.__class__ = }\") # The `__class__` attribute shows the type of the object, which is `torch.Tensor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]])\n"
     ]
    }
   ],
   "source": [
    "# Create a 2-dimensional tensor (column vector) ‚Üí A 2D tensor is a matrix with rows and columns\n",
    "column_vector = torch.tensor([[1], [2], [3], [4]]) # A column vector with 4 rows and 1 column\n",
    "print(column_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n"
     ]
    }
   ],
   "source": [
    "# Create a 2-dimensional tensor (matrix) ‚Üí A 2D tensor is a matrix with rows and columns\n",
    "matrix = torch.tensor(\n",
    "    [[1, 2, 3],\n",
    "     [4, 5, 6],\n",
    "     [7, 8, 9]]\n",
    ")\n",
    "print(matrix) # A 2D tensor with shape (3, 3), representing a 3x3 matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2, 2, 5],\n",
      "         [3, 4, 0, 8]],\n",
      "\n",
      "        [[5, 6, 6, 7],\n",
      "         [4, 8, 1, 2]],\n",
      "\n",
      "        [[1, 1, 8, 9],\n",
      "         [0, 0, 2, 3]]])\n"
     ]
    }
   ],
   "source": [
    "# Create a 3-dimensional tensor\n",
    "# A 3D tensor can be thought of as a collection of matrices (2D tensors) stacked along a third dimension\n",
    "# Here, the tensor is created from a nested list structure with three levels:\n",
    "# - The outer list represents the \"depth\" or \"channels\" (3 in this case).\n",
    "# - The middle lists represent the rows of each matrix (2 in this case).\n",
    "# - The inner lists represent the columns of each matrix (4 in this case).\n",
    "tensor_3d = torch.tensor(\n",
    "    [[[1, 2, 2, 5],\n",
    "      [3, 4, 0, 8]],\n",
    "\n",
    "     [[5, 6, 6, 7],\n",
    "      [4, 8, 1, 2]],\n",
    "\n",
    "     [[1, 1, 8, 9],\n",
    "      [0, 0, 2, 3]]]\n",
    ")\n",
    "print(tensor_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1, 2, 5, 4],\n",
      "          [3, 4, 1, 0]],\n",
      "\n",
      "         [[5, 6, 2, 3],\n",
      "          [7, 8, 6, 4]]]])\n"
     ]
    }
   ],
   "source": [
    "# Create a 4-dimensional tensor\n",
    "# A 4D tensor can be thought of as a collection of 3D tensors stacked along a fourth dimension\n",
    "# Here, the tensor is created from a nested list structure with four levels:\n",
    "# - The outer list represents the \"batch\" dimension (1 in this case).\n",
    "# - The next level represents the \"depth\" or \"channels\" (2 in this case).\n",
    "# - The next level represents the rows of each matrix (2 in this case).\n",
    "# - The innermost lists represent the columns of each matrix (4 in this case).\n",
    "tensor_4d = torch.tensor(\n",
    "    [[[[1, 2, 5, 4],\n",
    "       [3, 4, 1, 0]],\n",
    "      [[5, 6, 2, 3],\n",
    "       [7, 8, 6, 4]]]]\n",
    ")\n",
    "\n",
    "# A 4D tensor with shape (1, 2, 2, 4), representing:\n",
    "# - 1 batch\n",
    "# - 2 channels/depth\n",
    "# - Each channel has 2 rows and 4 columns\n",
    "print(tensor_4d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n"
     ]
    }
   ],
   "source": [
    "# Create a tuple of tuples, where each inner tuple contains two integers\n",
    "a = tuple([(1, 2), (3, 4), (5, 6)])\n",
    "tensor_a = torch.tensor(a) # Convert the tuple of tuples into a PyTorch tensor\n",
    "print(tensor_a) # The resulting tensor is a 2D tensor with shape (3, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='#ff555e2' size=\"4.5\" face=\"Arial\"><b>Getting information from tensors</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float32, device(type='cpu'))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Default datatype for tensors is float32\n",
    "float_32_tensor = torch.tensor([1.0, 5.0, 6.0],\n",
    "                               dtype=None, # defaults to None, which is torch.float32 or whatever datatype is passed\n",
    "                               device=None, # defaults to None, which uses the default tensor type\n",
    "                               requires_grad=False) # if True, operations performed on the tensor are recorded \n",
    "\n",
    "float_32_tensor.dtype, float_32_tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = tensor(1.3333, dtype=torch.float64) --> a.shape = torch.Size([]), a.ndim = 0, a.size() = torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "# Create a 0-dimensional tensor (scalar) ‚Üí A 0D tensor represents a single value, similar to a scalar in mathematics\n",
    "# The tensor is explicitly set to have a data type of `torch.float64` (64-bit floating point) and is placed on the CPU\n",
    "a = torch.tensor(4/3, dtype=torch.float64, device=\"cpu\")\n",
    "\n",
    "# - `a.shape`: The shape of the tensor (empty tuple for 0D tensors)\n",
    "# - `a.ndim`: The number of dimensions (0 for a scalar)\n",
    "# - `a.size()`: The size of the tensor (same as shape for 0D tensors)\n",
    "print(f\"{a = } --> {a.shape = }, {a.ndim = }, {a.size() = }\")\n",
    "\n",
    "# Convert the tensor to a different data type, `torch.float16` (16-bit floating point)\n",
    "# This reduces the precision of the tensor but can save memory and improve performance\n",
    "a_float16 = a.type(torch.float16)\n",
    "# Alternatively, you can use `a.short()` to convert to a 16-bit integer, but this is not applicable here since the tensor is floating-point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#ff0051e2\" size=\"4.5\" face=\"Arial\"><b>Math Operations</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 2.0, Standard Deviation: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Create a 1-dimensional tensor (vector) with integer values\n",
    "a = torch.tensor([1, 2, 3])\n",
    "\n",
    "# Convert the tensor to `float` type using `.float()` to ensure the mean is computed as a floating-point value\n",
    "mean_value = a.float().mean() # Calculate the mean of the tensor\n",
    "\n",
    "# Convert the tensor to `torch.float32` type using `.type(torch.float32)` to ensure the standard deviation is computed as a floating-point value\n",
    "std_value = a.type(torch.float32).std() # Calculate the standard deviation of the tensor\n",
    "print(f\"Mean: {mean_value}, Standard Deviation: {std_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[3, 6],\n",
       "         [5, 0]]),\n",
       " tensor([[3, 2],\n",
       "         [7, 9]]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create two 2D tensors (matrices) with random integer values between 0 and 10\n",
    "a = torch.randint(10, (2, 2))  # 2x2 tensor\n",
    "b = torch.randint(10, (2, 2))  # 2x2 tensor\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 6,  8],\n",
       "         [12,  9]]),\n",
       " tensor([[ 0,  4],\n",
       "         [-2, -9]]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adds corresponding elements of `a` and `b`\n",
    "# Subtracts elements of `b` from corresponding elements of `a`\n",
    "torch.add(a, b, ), torch.sub(a, b, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element-wise multiplication:\n",
      "tensor([[ 9, 12],\n",
      "        [35,  0]])\n",
      "Matrix multiplication (using @):\n",
      "tensor([[51, 60],\n",
      "        [15, 10]])\n",
      "Matrix multiplication (using torch.matmul):\n",
      "tensor([[51, 60],\n",
      "        [15, 10]])\n"
     ]
    }
   ],
   "source": [
    "# Element-wise multiplication using `*` (Multiplies corresponding elements of `a` and `b`)\n",
    "elementwise_mul = a * b\n",
    "\n",
    "# Matrix multiplication using `@` (Performs matrix multiplication of `a` and `b`)\n",
    "matrix_mul = a @ b\n",
    "\n",
    "# Matrix multiplication using `torch.matmul()` (Performs matrix multiplication of `a` and `b`)\n",
    "matmul_result = torch.matmul(a, b)\n",
    "\n",
    "print(f\"Element-wise multiplication:\\n{elementwise_mul}\")\n",
    "print(f\"Matrix multiplication (using @):\\n{matrix_mul}\")\n",
    "print(f\"Matrix multiplication (using torch.matmul):\\n{matmul_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element-wise division:\n",
      "tensor([[0.4000, 1.2500],\n",
      "        [4.0000, 4.0000]])\n"
     ]
    }
   ],
   "source": [
    "# Perform element-wise division of two 2D tensors `a` and `b`\n",
    "a = torch.randint(10, (2, 2))  # 2x2 tensor with random integer values between 0 and 10\n",
    "b = torch.randint(1, 10, (2, 2))  # 2x2 tensor with random integer values between 1 and 10 (to avoid division by zero)\n",
    "\n",
    "# Element-wise division using `/` (Divides corresponding elements of `a` by `b`)\n",
    "elementwise_div = a / b\n",
    "print(f\"Element-wise division:\\n{elementwise_div}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#00ff21aa\" size=\"4.5\" face=\"Arial\"><b>Special Arrays</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a 2D tensor filled with ones\n",
    "torch.ones((2, 1))  # The tensor has a shape of (2, 1), meaning it has 2 rows and 1 column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a 3D tensor filled with zeros\n",
    "# The tensor has a shape of (3, 4, 3), meaning:\n",
    "# - 3 matrices (depth/channels)\n",
    "# - Each matrix has 4 rows and 3 columns\n",
    "torch.zeros((3, 4, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The tensor has a shape of (5, 4), meaning it has 5 rows and 4 columns\n",
    "torch.eye(5, 4) # The diagonal elements are set to 1, and all other elements are set to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 2, 2],\n",
       "        [2, 2, 2],\n",
       "        [2, 2, 2],\n",
       "        [2, 2, 2]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The tensor has a shape of (4, 3), meaning it has 4 rows and 3 columns\n",
    "torch.full([4, 3], fill_value=2) # All elements in the tensor are set to the `fill_value` (2 in this case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#22aa1232\" size=\"4.5\" face=\"Arial\"><b>Random Arrays</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4657, 0.2328, 0.4527],\n",
       "        [0.5871, 0.4086, 0.1272],\n",
       "        [0.6373, 0.2421, 0.7312],\n",
       "        [0.7224, 0.1992, 0.6948]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(12) # Set a manual seed for reproducibility\n",
    "torch.rand((4, 3)) # Create a 2D tensor with random values uniformly distributed between 0 and 1 (shape of (4, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[12,  3,  9],\n",
       "        [11,  2, 10],\n",
       "        [ 8,  3,  3],\n",
       "        [10, 11,  2]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set a manual seed for reproducibility\n",
    "torch.manual_seed(12)\n",
    "\n",
    "# Create a 2D tensor with random integer values within a specified range\n",
    "torch.randint(2, 13, (4, 3)) # The range is from 2 (inclusive) to 13 (exclusive) and a shape of (4, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#22aa1232\" size=\"4.5\" face=\"Arial\"><b>Randperm & permute</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 8, 7, 6, 4, 5, 2, 9, 1, 0])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random permutation of integers from 0 to 9\n",
    "torch.randperm(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous shape: torch.Size([224, 224, 3])\n",
      "New shape: torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor with a specific shape (224, 224, 3) using random values\n",
    "# This shape is commonly used for RGB images, where:\n",
    "# - 224 is the height\n",
    "# - 224 is the width\n",
    "# - 3 is the number of color channels (Red, Green, Blue)\n",
    "original = torch.rand(size=(224, 224, 3))\n",
    "\n",
    "# Permute the tensor to rearrange the order of its axes\n",
    "# The `permute()` method reorders the dimensions of the tensor\n",
    "# Here, the new order is (2, 0, 1), which means:\n",
    "# - The original axis 2 (channels) becomes the new axis 0\n",
    "# - The original axis 0 (height) becomes the new axis 1\n",
    "# - The original axis 1 (width) becomes the new axis 2\n",
    "permuted = original.permute(2, 0, 1)\n",
    "print(f\"Previous shape: {original.shape}\")\n",
    "print(f\"New shape: {permuted.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#bb1254ff\" size=\"4.5\" face=\"Arial\"><b>Indexing & Slicing</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: tensor([ 1.1538,  0.3991,  0.2250,  0.2924,  0.0614, -0.2668, -1.3685, -1.1728,\n",
      "         0.1342, -0.2616, -1.5436,  0.2017])\n",
      "a[0:1]: tensor([1.1538])\n",
      "a[0]: 1.1538151502609253\n",
      "a[[0, 2, 7]]: tensor([ 1.1538,  0.2250, -1.1728])\n"
     ]
    }
   ],
   "source": [
    "# Create a 1D tensor with 12 random values from a standard normal distribution (mean=0, std=1)\n",
    "a = torch.randn(12)\n",
    "print(f\"a: {a}\")\n",
    "print(f\"a[0:1]: {a[0:1]}\") # A slice of the tensor containing the first element (as a 1D tensor)\n",
    "print(f\"a[0]: {a[0]}\")     # The first element of the tensor (as a scalar)\n",
    "print(f\"a[[0, 2, 7]]: {a[[0, 2, 7]]}\") # A tensor containing the elements at indices 0, 2, and 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.2250,  0.0614, -1.3685,  0.1342, -1.5436]),\n",
       " tensor([ 0.2250,  0.0614, -1.3685,  0.1342, -1.5436]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `a[2:12:2]`: Slice the tensor from index 2 to index 12 (exclusive) with a step of 2\n",
    "# `a[2::2]`: Slice the tensor from index 2 to the end with a step of 2\n",
    "a[2:12:2], a[2::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:\n",
      "tensor([[ 0.7994,  0.7085,  1.2263,  0.9413, -0.4132],\n",
      "        [ 0.1620,  0.4401,  0.5386, -0.2449, -0.0299],\n",
      "        [ 1.1947,  1.9144,  0.3186, -1.5708,  0.6851]])\n",
      "a[0:3, 2:-1]:\n",
      "tensor([[ 1.2263,  0.9413],\n",
      "        [ 0.5386, -0.2449],\n",
      "        [ 0.3186, -1.5708]])\n",
      "a[:, 2:-1]:\n",
      "tensor([[ 1.2263,  0.9413],\n",
      "        [ 0.5386, -0.2449],\n",
      "        [ 0.3186, -1.5708]])\n"
     ]
    }
   ],
   "source": [
    "# Create a 2D tensor with random values from a standard normal distribution (mean=0, std=1)\n",
    "a = torch.randn(3, 5) # The tensor has a shape of (3, 5), meaning 3 rows and 5 columns\n",
    "print(f\"a:\\n{a}\")\n",
    "print(f\"a[0:3, 2:-1]:\\n{a[0:3, 2:-1]}\") # Slice rows from 0 to 3 (exclusive) and columns from 2 to -1 (exclusive)\n",
    "print(f\"a[:, 2:-1]:\\n{a[:, 2:-1]}\") # Slice all rows and columns from 2 to -1 (exclusive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:\n",
      "tensor([[ 0.7994,  0.7085,  1.2263,  0.9413, -0.4132],\n",
      "        [ 0.1620,  0.4401,  0.5386, -0.2449, -0.0299],\n",
      "        [ 1.1947,  1.9144,  0.3186, -1.5708,  0.6851]])\n",
      "a[0:2]:\n",
      "tensor([[ 0.7994,  0.7085,  1.2263,  0.9413, -0.4132],\n",
      "        [ 0.1620,  0.4401,  0.5386, -0.2449, -0.0299]])\n",
      "a[0:2, :]:\n",
      "tensor([[ 0.7994,  0.7085,  1.2263,  0.9413, -0.4132],\n",
      "        [ 0.1620,  0.4401,  0.5386, -0.2449, -0.0299]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"a:\\n{a}\")\n",
    "print(f\"a[0:2]:\\n{a[0:2]}\") # Slice rows from 0 to 2 (exclusive)\n",
    "print(f\"a[0:2, :]:\\n{a[0:2, :]}\") # Slice rows from 0 to 2 (exclusive) and all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:\n",
      "tensor([[ 0.7994,  0.7085,  1.2263,  0.9413, -0.4132],\n",
      "        [ 0.1620,  0.4401,  0.5386, -0.2449, -0.0299],\n",
      "        [ 1.1947,  1.9144,  0.3186, -1.5708,  0.6851]])\n",
      "a[::2, 2:]:\n",
      "tensor([[ 1.2263,  0.9413, -0.4132],\n",
      "        [ 0.3186, -1.5708,  0.6851]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"a:\\n{a}\")\n",
    "print(f\"a[::2, 2:]:\\n{a[::2, 2:]}\") # Slice rows with a step of 2 and columns from index 2 to the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a shape: torch.Size([4, 6, 7])\n",
      "a[1:2, 3:5, 2:4]:\n",
      "tensor([[[-0.0007, -0.3963],\n",
      "         [ 0.0420,  0.3955]]])\n",
      "a[[1], 3:5, 2:4]:\n",
      "tensor([[[-0.0007, -0.3963],\n",
      "         [ 0.0420,  0.3955]]])\n",
      "a[1, 3:5, 2:4]:\n",
      "tensor([[-0.0007, -0.3963],\n",
      "        [ 0.0420,  0.3955]])\n"
     ]
    }
   ],
   "source": [
    "# Create a 3D tensor with random values from a standard normal distribution (mean=0, std=1)\n",
    "# The tensor has a shape of (4, 6, 7), meaning:4 matrices (depth/channels); Each matrix has 6 rows and 7 columns\n",
    "a = torch.randn(4, 6, 7)\n",
    "print(f\"a shape: {a.shape}\")\n",
    "print(f\"a[1:2, 3:5, 2:4]:\\n{a[1:2, 3:5, 2:4]}\") # Slice along all three dimensions\n",
    "print(f\"a[[1], 3:5, 2:4]:\\n{a[[1], 3:5, 2:4]}\") # Slice using a list for the first dimension\n",
    "print(f\"a[1, 3:5, 2:4]:\\n{a[1, 3:5, 2:4]}\") # Slice the first dimension using a single index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a shape: torch.Size([4, 6, 7])\n",
      "a[1]:\n",
      "tensor([[ 6.8439e-01,  8.1566e-01,  7.4491e-01, -2.4087e+00,  1.1425e+00,\n",
      "         -6.8747e-01,  8.3663e-01],\n",
      "        [ 2.3537e-01,  2.3076e-01, -8.8154e-02,  4.3994e-01,  9.2753e-01,\n",
      "         -5.9913e-01,  7.2422e-01],\n",
      "        [-4.8125e-01, -2.4103e-01,  1.4419e+00,  4.8136e-01,  1.6973e+00,\n",
      "          1.4827e-01,  1.3748e+00],\n",
      "        [-4.9702e-01,  8.0428e-01, -6.6563e-04, -3.9632e-01, -7.3325e-01,\n",
      "         -2.0131e-01, -8.6179e-01],\n",
      "        [ 1.3646e-01, -2.2297e+00,  4.2036e-02,  3.9549e-01,  1.0890e-01,\n",
      "          1.6878e+00,  1.4641e+00],\n",
      "        [ 2.8444e-01, -4.5102e-01, -8.2112e-01,  5.2210e-02, -7.0324e-01,\n",
      "         -1.3335e+00, -6.7759e-01]])\n",
      "a[:, :, -1]:\n",
      "tensor([[-0.0088,  1.5679, -0.7508,  0.6052, -0.7827,  0.5927],\n",
      "        [ 0.8366,  0.7242,  1.3748, -0.8618,  1.4641, -0.6776],\n",
      "        [ 0.3287,  0.4143, -1.7965,  2.1164,  0.2472, -1.2820],\n",
      "        [ 1.3255,  0.7496, -0.6324,  0.3026,  1.7560, -3.0773]])\n",
      "a[..., -1]:\n",
      "tensor([[-0.0088,  1.5679, -0.7508,  0.6052, -0.7827,  0.5927],\n",
      "        [ 0.8366,  0.7242,  1.3748, -0.8618,  1.4641, -0.6776],\n",
      "        [ 0.3287,  0.4143, -1.7965,  2.1164,  0.2472, -1.2820],\n",
      "        [ 1.3255,  0.7496, -0.6324,  0.3026,  1.7560, -3.0773]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"a shape: {a.shape}\")\n",
    "print(f\"a[1]:\\n{a[1]}\") # Select the second matrix (index 1) along the first dimension\n",
    "print(f\"a[:, :, -1]:\\n{a[:, :, -1]}\") # Select the last column from all matrices and all rows\n",
    "print(f\"a[..., -1]:\\n{a[..., -1]}\") # Same as above, using `...` (ellipsis) to represent all dimensions except the last"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#aaff5499\" size=\"4.5\" face=\"Arial\"><b>Unsqueeze & squeeze</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape of tensor_a: torch.Size([1, 3, 1, 4, 1])\n",
      "Squeezed shape of tensor_b: torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor with singleton dimensions (dimensions of size 1)\n",
    "# The tensor has a shape of (1, 3, 1, 4, 1), meaning:\n",
    "# - 1 matrix (depth/channels)\n",
    "# - 3 rows\n",
    "# - 1 column\n",
    "# - 4 channels\n",
    "# - 1 additional singleton dimension\n",
    "tensor_a = torch.randn(1, 3, 1, 4, 1)\n",
    "print(\"Original shape of tensor_a:\", tensor_a.shape)\n",
    "\n",
    "# Remove all singleton dimensions using the `squeeze()` method (This eliminates dimensions of size 1)\n",
    "tensor_b = tensor_a.squeeze()\n",
    "print(\"Squeezed shape of tensor_b:\", tensor_b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape of a: torch.Size([2, 1, 3, 1, 4])\n",
      "a.squeeze(0).shape = torch.Size([2, 1, 3, 1, 4])\n",
      "a.squeeze(1).shape = torch.Size([2, 3, 1, 4])\n",
      "a.squeeze(3).shape = torch.Size([2, 1, 3, 4])\n",
      "a.squeeze().shape = torch.Size([2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "# Removing a specific singleton dimension\n",
    "a = torch.randn(2, 1, 3, 1, 4)\n",
    "print(\"Original shape of a:\", a.shape)  # Output: torch.Size([2, 1, 3, 1, 4])\n",
    "\n",
    "# Remove the first dimension (index 0) which is not 1, so no change is done; Output: torch.Size([2, 1, 3, 1, 4])\n",
    "print(f\"{a.squeeze(0).shape = }\")\n",
    "\n",
    "# Remove the second dimension (index 1) which is size 1; Output: torch.Size([2, 3, 1, 4])\n",
    "print(f\"{a.squeeze(1).shape = }\")\n",
    "\n",
    "# Remove the fourth dimension (index 3) which is size 1; Output: torch.Size([2, 1, 3, 4])\n",
    "print(f\"{a.squeeze(3).shape = }\")\n",
    "\n",
    "print(f\"{a.squeeze().shape = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: tensor([[ 0.0940,  0.0286],\n",
      "        [ 0.3817, -0.1718]])\n",
      "b.unsqueeze(0) = tensor([[[ 0.0940,  0.0286],\n",
      "         [ 0.3817, -0.1718]]]) --> b.unsqueeze(0).shape = torch.Size([1, 2, 2])\n",
      "b.unsqueeze(1) = tensor([[[ 0.0940,  0.0286]],\n",
      "\n",
      "        [[ 0.3817, -0.1718]]]) --> b.unsqueeze(1).shape = torch.Size([2, 1, 2])\n",
      "b.unsqueeze(2) = tensor([[[ 0.0940],\n",
      "         [ 0.0286]],\n",
      "\n",
      "        [[ 0.3817],\n",
      "         [-0.1718]]]) --> b.unsqueeze(2).shape = torch.Size([2, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "b = torch.randn(2, 2)\n",
    "print(\"Original:\", b)  # Output: torch.Size([3, 4])\n",
    "\n",
    "# Add dimension at the beginning (index 0); # Output: torch.Size([1, 3, 4])\n",
    "print(f\"{b.unsqueeze(0) = } --> {b.unsqueeze(0).shape = }\")\n",
    "# Add dimension in between the two dimensions (index 1); Output: torch.Size([3, 1, 4])\n",
    "print(f\"{b.unsqueeze(1) = } --> {b.unsqueeze(1).shape = }\")\n",
    "\n",
    "# Add dimension at the end (index 2); Output: torch.Size([3, 4, 1])\n",
    "print(f\"{b.unsqueeze(2) = } --> {b.unsqueeze(2).shape = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='#hh99gg99' size='4.5' face=\"Arial\"><b>PyTorch tensors & NumPy</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array: [1. 2. 3. 4. 5. 6. 7.]\n",
      "tensor: tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64)\n",
      "nump: [1. 2. 3. 4. 5. 6. 7.]\n"
     ]
    }
   ],
   "source": [
    "array = np.arange(1.0, 8.0) # Create a NumPy array with values ranging from 1.0 to 8.0 (exclusive)\n",
    "tensor = torch.from_numpy(array) # Convert the NumPy array to a PyTorch tensor\n",
    "nump = torch.Tensor.numpy(tensor) # Convert the PyTorch tensor back to a NumPy array\n",
    "print(f\"array: {array}\")\n",
    "print(f\"tensor: {tensor}\")\n",
    "print(f\"nump: {nump}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
